---
title: "Econometrics II TA Session #3"
author: "Hiroki Kato"
output:
  pdf_document:
    latex_engine: xelatex
    md_extensions: +raw_attribute
    number_sections: true
    extra_dependencies: ["xcolor"]
    keep_tex: yes
fontsize: 12pt
header-includes:
  - \usepackage{zxjatype}
  - \setCJKmainfont[BoldFont = IPAゴシック]{IPA明朝}
  - \setCJKsansfont{IPAゴシック}
  - \setCJKmonofont{IPAゴシック}
  - \parindent = 1em
  - \newcommand{\argmax}{\mathop{\rm arg~max}\limits}
  - \newcommand{\argmin}{\mathop{\rm arg~min}\limits}
  - \DeclareMathOperator*{\plim}{plim}
---

```{r setup, include = FALSE, echo = FALSE, purl = FALSE}
# This is options to make pdf file. You should ignore
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  echo = TRUE, 
  cache = FALSE,
  fig.pos = "h")
knitr::opts_knit$set(root.dir = "C:/Users/katoo/Desktop/2020EconometricsTA/R")
```

# Empirical Application of Binary Model: Titanic Survivors

**Brief Background**.
"Women and children first" is a behavioral norm,
which women and children are saved first in a life-threatening situation.
This code was made famous by the sinking of the Titanic in 1912.
An empirical application investigates characteristics of survivors of Titanic
to answer whether crews obeyed the code or not.

\noindent
**Data**.
We use an open data about Titanic survivors [^source].
Although this dataset contains many variables,
we use only four variables: `survived`, `age`, `fare`, and `sex`.
We summarize descpritons of variables as follows:

- `survived`: a binary variable taking 1 if a passenger survived.
- `age`: a continuous variable representing passeger's age.
- `fare`: a continuous variable representing how much passeger paid.
- `sex`: a string variable representing passenger's sex.

Using `sex`, we will make a binary variable, called `female`, taking 1 if passeger is female.
Intead of `sex`, we use `female` variable in regression.

[^source]: data source: <http://biostat.mc.vanderbilt.edu/DataSets>.

```{r data}
dt <- read.csv(
  file = "./data/titanic.csv", 
  header = TRUE,  sep = ",", row.names = NULL,  stringsAsFactors = FALSE)

dt$female <- ifelse(dt$sex == "female", 1, 0)
dt <- subset(dt, !is.na(survived)&!is.na(age)&!is.na(fare)&!is.na(female))

dt <- dt[,c("survived", "age", "fare", "female")]
head(dt)
```

\noindent
**Model**.
In a binary model, a dependent (outcome) variable $y_i$ takes only two values, i.e., $y_i \in \{0, 1\}$.
A binary variable is sometimes called a *dummy* variable.
In this application, the outcome variable is `survived`.
Explanatory variables are `female`, `age`, and `fare`.
The regression function is 
\begin{equation*}
  \begin{split}
    &\mathbb{E}[survived | female, age, fare] \\
    =& \mathbb{P}[survived = 1 | female, age, fare]
    = G(\beta_0 + \beta_1 female + \beta_2 age + \beta3 fare).
  \end{split}
\end{equation*}
The function $G(\cdot)$ is arbitrary function. In practice, we often use following three specifications:

- Linear probability model (LPM): $G(\mathbf{x}_i \beta) = \mathbf{x}_i \beta$.
- Probit model: $G(\mathbf{x}_i \beta) = \Phi(\mathbf{x}_i \beta)$ where $\Phi(\cdot)$ is the standard Gaussian cumulative function.
- Logit model: $G(\mathbf{x}_i \beta) = 1/(1 + \exp(-\mathbf{x}_i \beta))$.

## Linear Probability Model

The linear probability model specifys that $G(a)$ is linear in $a$, that is, 
\begin{equation*}
  \mathbb{P}[survived = 1 | female, age, fare]
  = \beta_0 + \beta_1 female + \beta_2 age + \beta3 fare.
\end{equation*}
This model can be estimated using the OLS method.
In `R`, we can use the OLS method, running `lm()` function.

```{R ols}
model <- survived ~ female + age + fare
LPM <- lm(model, data = dt)
```
However, `lm()` function does not deal with heteroskedasticity problem.
To resolve it, we need to claculate heteroskedasticity-robust standard errors using the White method.
\begin{equation*}
  \hat{V}(\hat{\beta}) =
  \left( \frac{1}{n} \sum_i \mathbf{x}'_i \mathbf{x}_i  \right)^{-1}
  \left( \frac{1}{n} \sum_i \hat{u}_i^2 \mathbf{x}'_i \mathbf{x}_i \right)
  \left( \frac{1}{n} \sum_i \mathbf{x}'_i \mathbf{x}_i \right)^{-1}
\end{equation*}

```{r RobustSE}
# heteroskedasticity-robust standard errors
dt$"(Intercept)" <- 1
X <- as.matrix(dt[,c("(Intercept)", "female", "age", "fare")])
u <- diag(LPM$residuals^2)

XX <- t(X) %*% X
avgXX <- XX * nrow(X)^{-1}
inv_avgXX <- solve(avgXX)

uXX <- t(X) %*% u %*% X
avguXX <- uXX * nrow(X)^{-1} 

vcov_b <- (inv_avgXX %*% avguXX %*% inv_avgXX) * nrow(X)^{-1}
rse_b <- sqrt(diag(vcov_b))

# homoskedasticity-based standard errors
se_b <- sqrt(diag(vcov(LPM)))

print("The Variance of OLS"); vcov(LPM)
print("The Robust variance of OLS"); vcov_b
print("The Robust se using White method"); rse_b
print("The Robust t-value using White method"); coef(LPM)/rse_b
```

Using the package `lmtest` and `sandwich` is 
the most easiest way to calculate heteroskedasticity-robust standard errors and $t$-statistics.

```{r lmtest}
library(lmtest) #use function `coeftest`
library(sandwich) #use function `vcovHC`
coeftest(LPM, vcov = vcovHC(LPM, type = "HC0"))[, "Std. Error"]
coeftest(LPM, vcov = vcovHC(LPM, type = "HC0"))[, "t value"]
```

Finally, we obtain follwing results of linear probability model.
We will discuss interpretation of results and goodness-of-fit of LPM later.

```{r LPM_result, results = "asis"}
# t-stats
t_b <- coef(LPM)/se_b 
rt_b <- coef(LPM)/rse_b
# p-value Pr( > |t|)
p_b <- pt(abs(t_b), df = nrow(X)-ncol(X), lower = FALSE)*2
rp_b <- pt(abs(rt_b), df = nrow(X)-ncol(X), lower = FALSE)*2

library(stargazer)
stargazer(
  LPM, LPM,
  se = list(se_b, rse_b), t = list(t_b, rt_b), p = list(p_b, rp_b),
  t.auto = FALSE, p.auto = FALSE,
  report = "vcstp", keep.stat = c("n"),
  add.lines = list(
    c("Standard errors", "Homoskedasticity-based", "Heteroskedasticity-robust")),
  title = "Results of Linear Probability Model",
  type = "latex", header = FALSE, font.size = "small",
  omit.table.layout = "n"
)
```