---
title: "Econometrics II TA Session #3"
author: "Hiroki Kato"
output:
  pdf_document:
    latex_engine: xelatex
    md_extensions: +raw_attribute
    number_sections: true
    extra_dependencies: ["xcolor"]
    keep_tex: yes
fontsize: 12pt
header-includes:
  - \usepackage{zxjatype}
  - \setCJKmainfont[BoldFont = IPAゴシック]{IPA明朝}
  - \setCJKsansfont{IPAゴシック}
  - \setCJKmonofont{IPAゴシック}
  - \parindent = 1em
  - \newcommand{\argmax}{\mathop{\rm arg~max}\limits}
  - \newcommand{\argmin}{\mathop{\rm arg~min}\limits}
  - \DeclareMathOperator*{\plim}{plim}
---

```{r setup, include = FALSE, echo = FALSE, purl = FALSE}
# This is options to make pdf file. You should ignore
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  echo = TRUE, 
  cache = FALSE,
  fig.pos = "h")
knitr::opts_knit$set(root.dir = "C:/Users/katoo/Desktop/2020EconometricsTA/R")
```

# Empirical Application of Binary Model: Racial Discrimination in Court

**Brief Background**.
Recently, in the U.S., anti-racism activities called "Black Lives Matter" are getting hot.
These activities stems from the death of George Floyd,
who was killed by a white police officer on May 25, 2020.
The empirical application of binary model investigates 
whether the judgement of death penalty is based on race of defendant and race of victim.

\noindent
**Data**.
The package `catdata` contains many built-in dataets which include categorical variables.
We use the built-in dataset `deathpenalty` which is about the death-penalty judgement of defendants 
in cases of multiple murders in Florida between 1976 and 1987.

```{r data}
dt <- read.csv(
  file = "./data/titanic.csv", 
  header = TRUE,  sep = ",", row.names = NULL,  stringsAsFactors = FALSE)
dt <- dt[,c("survived", "age", "fare", "sex")]
head(dt)
```

This dataset contains three dummy variables

1. `DeathPenalty` is a dummy variable taking 1 if the judgement is death penalty.
2. `VictimRace` is a dummy variable taking 1 if the race of the victim is white.
3. `DefendantRace` is a dummy variable taking 1 if the race of the defendant is white.

This dataset aggregates observations with repect to `DeathPenalty`, `VictimRace` and `DefendantRace`.
The variable `Freq` represents the number of observations.
Since it is inconvinient for us to use the original data for estimation,
we disaggregate this dataset.
For example, we make 37 rows whose elements are `DeathPenalty = 0`, `VictimRace = 1`, and `DefendantRace = 0` because 
there are 37 obaservations, i.e., `Freq = 37`.

```{r preprocess}
dt <- subset(dt, !is.na(survived)&!is.na(age)&!is.na(fare)&!is.na(sex))
dt$female <- ifelse(dt$sex == "female", 1, 0)
```

\noindent
**Model**.
In a binary model, a dependent (outcome) variable $y_i$ takes only two values, i.e., $y_i \in \{0, 1\}$.
A binary variable is sometimes called a *dummy* variable.
In this application, the outcome variable is `DeathPenalty` taking 1 if the judgement is death penalty.
We make three explanatory variables.

1. `WB` is a dummy variable taking 1 if the race of the victim and the defendant is white and black, respectively.
2. `BW` is a dummy variable taking 1 if the race of the victim and the defendant is black and white, respectively.
3. `WW` is a dummy variable taking 1 if the race of both the victim and the defendant is black.

The regression function is 
\begin{equation*}
  \begin{split}
    &\mathbb{E}[DeathPenalty | WB, BW, WW] \\
    =& \mathbb{P}[DeathPenalty = 1 | WB, BW, WW]
    = G(\beta_0 + \beta_1 WB + \beta_2 BW + \beta3 WW).
  \end{split}
\end{equation*}
The function $G(\cdot)$ is arbitrary function. In practice, we often use following three specifications:

- Linear probability model (LPM): $G(\mathbf{x}_i \beta) = \mathbf{x}_i \beta$.
- Probit model: $G(\mathbf{x}_i \beta) = \Phi(\mathbf{x}_i \beta)$ where $\Phi(\cdot)$ is the standard Gaussian cumulative function.
- Logit model: $G(\mathbf{x}_i \beta) = 1/(1 + \exp(-\mathbf{x}_i \beta))$.

## Linear Probability Model

The linear probability model is 
\begin{equation*}
  \mathbb{P}[DeathPenalty = 1 | WB, BW, WW]
  = \beta_0 + \beta_1 WB + \beta_2 BW + \beta3 WW
\end{equation*}
This model can be estimated using the OLS method.
In `R`, we can use the OLS method, running `lm()` function.

```{R ols}
model <- survived ~ female + age + fare
LPM <- lm(model, data = dt)
```
However, `lm()` function does not deal with heteroskedasticity problem.
To resolve it, we need to claculate heteroskedasticity-robust standard errors using the White method.
\begin{equation*}
  \hat{V}(\hat{\beta}) =
  \left( \frac{1}{n} \sum_i \mathbf{x}'_i \mathbf{x}_i  \right)^{-1}
  \left( \frac{1}{n} \sum_i \hat{u}_i^2 \mathbf{x}'_i \mathbf{x}_i \right)
  \left( \frac{1}{n} \sum_i \mathbf{x}'_i \mathbf{x}_i \right)^{-1}
\end{equation*}

```{r RobustSE}
# heteroskedasticity-robust standard errors
dt$"(Intercept)" <- 1
X <- as.matrix(dt[,c("(Intercept)", "female", "age", "fare")])
u <- diag(LPM$residuals^2)

XX <- t(X) %*% X
avgXX <- XX * nrow(X)^{-1}
inv_avgXX <- solve(avgXX)

uXX <- t(X) %*% u %*% X
avguXX <- uXX * nrow(X)^{-1} 

vcov_b <- (inv_avgXX %*% avguXX %*% inv_avgXX) * nrow(X)^{-1}
rse_b <- sqrt(diag(vcov_b))

# homoskedasticity-based standard errors
se_b <- sqrt(diag(vcov(LPM)))

print("The Variance of OLS"); vcov(LPM)
print("The Robust variance of OLS"); vcov_b
print("The Robust se using White method"); rse_b
print("The Robust t-value using White method"); coef(LPM)/rse_b
```

Using the package `lmtest` and `sandwich` is 
the most easiest way to calculate heteroskedasticity-robust standard errors and $t$-statistics.

```{r lmtest}
library(lmtest) #use function `coeftest`
library(sandwich) #use function `vcovHC`
coeftest(LPM, vcov = vcovHC(LPM, type = "HC0"))[, "Std. Error"]
coeftest(LPM, vcov = vcovHC(LPM, type = "HC0"))[, "t value"]
```

Finally, we obtain follwing results of linear probability model.
We will discuss interpretation of results and goodness-of-fit of LPM later.

```{r LPM_result, results = "asis"}
# t-stats
t_b <- coef(LPM)/se_b 
rt_b <- coef(LPM)/rse_b
# p-value Pr( > |t|)
p_b <- pt(abs(t_b), df = nrow(X)-ncol(X), lower = FALSE)*2
rp_b <- pt(abs(rt_b), df = nrow(X)-ncol(X), lower = FALSE)*2

library(stargazer)
stargazer(
  LPM, LPM,
  se = list(se_b, rse_b), t = list(t_b, rt_b), p = list(p_b, rp_b),
  t.auto = FALSE, p.auto = FALSE,
  report = "vcstp", keep.stat = c("n"),
  add.lines = list(
    c("Standard errors", "Homoskedasticity-based", "Heteroskedasticity-robust")),
  title = "Results of Linear Probability Model",
  type = "latex", header = FALSE, font.size = "small",
  omit.table.layout = "n"
)
```