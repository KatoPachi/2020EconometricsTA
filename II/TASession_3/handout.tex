% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  12pt,
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Econometrics II TA Session \#3},
  pdfauthor={Hiroki Kato},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{zxjatype}
\setCJKmainfont[BoldFont = IPAゴシック]{IPA明朝}
\setCJKsansfont{IPAゴシック}
\setCJKmonofont{IPAゴシック}
\parindent = 1em
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\argmin}{\mathop{\rm arg~min}\limits}
\DeclareMathOperator*{\plim}{plim}
\usepackage{xcolor}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Econometrics II TA Session \#3}
\author{Hiroki Kato}
\date{}

\begin{document}
\maketitle

\hypertarget{empirical-application-of-binary-model-titanic-survivors}{%
\section{Empirical Application of Binary Model: Titanic
Survivors}\label{empirical-application-of-binary-model-titanic-survivors}}

\textbf{Brief Background}. ``Women and children first'' is a behavioral
norm, which women and children are saved first in a life-threatening
situation. This code was made famous by the sinking of the Titanic in
1912. An empirical application investigates characteristics of survivors
of Titanic to answer whether crews obeyed the code or not.

\noindent \textbf{Data}. We use an open data about Titanic survivors
\footnote{data source: \url{http://biostat.mc.vanderbilt.edu/DataSets}.}.
Although this dataset contains many variables, we use only four
variables: \texttt{survived}, \texttt{age}, \texttt{fare}, and
\texttt{sex}. We summarize descriptions of variables as follows:

\begin{itemize}
\tightlist
\item
  \texttt{survived}: a binary variable taking 1 if a passenger survived.
\item
  \texttt{age}: a continuous variable representing passeger's age.
\item
  \texttt{fare}: a continuous variable representing how much passeger
  paid.
\item
  \texttt{sex}: a string variable representing passenger's sex.
\end{itemize}

Using \texttt{sex}, we will make a binary variable, called
\texttt{female}, taking 1 if passeger is female. Intead of \texttt{sex},
we use \texttt{female} variable in regression.

Moreover, we split data into two subsets: the \emph{training} data and
the \emph{test} data. The training data is randomly drawn from the
original data. The sample size of this data is two thirs of total
observations. We use the training data (\emph{in-sample}) to estimate
and evaluate model fitness. The test data consists of observations which
the training data does not include. We use the test data
(\emph{out-of-sample}) to evaluate model prediction.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dt \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}
  \DataTypeTok{file =} \StringTok{"./data/titanic.csv"}\NormalTok{, }
  \DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{,  }\DataTypeTok{sep =} \StringTok{","}\NormalTok{, }\DataTypeTok{row.names =} \OtherTok{NULL}\NormalTok{,  }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}

\NormalTok{dt}\OperatorTok{$}\NormalTok{female \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(dt}\OperatorTok{$}\NormalTok{sex }\OperatorTok{==}\StringTok{ "female"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{dt \textless{}{-}}\StringTok{ }\KeywordTok{subset}\NormalTok{(dt, }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(survived)}\OperatorTok{\&!}\KeywordTok{is.na}\NormalTok{(age)}\OperatorTok{\&!}\KeywordTok{is.na}\NormalTok{(fare)}\OperatorTok{\&!}\KeywordTok{is.na}\NormalTok{(female))}
\NormalTok{dt \textless{}{-}}\StringTok{ }\NormalTok{dt[,}\KeywordTok{c}\NormalTok{(}\StringTok{"survived"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{, }\StringTok{"female"}\NormalTok{)]}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{120511}\NormalTok{)}
\NormalTok{train\_id \textless{}{-}}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(dt), }\DataTypeTok{size =}\NormalTok{ (}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{)}\OperatorTok{*}\KeywordTok{nrow}\NormalTok{(dt), }\DataTypeTok{replace =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{train\_dt \textless{}{-}}\StringTok{ }\NormalTok{dt[train\_id,]}
\NormalTok{test\_dt \textless{}{-}}\StringTok{ }\NormalTok{dt[}\OperatorTok{{-}}\NormalTok{train\_id,]}

\KeywordTok{head}\NormalTok{(dt)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   survived   age     fare female
## 1        1 29.00 211.3375      1
## 2        1  0.92 151.5500      0
## 3        0  2.00 151.5500      1
## 4        0 30.00 151.5500      0
## 5        0 25.00 151.5500      1
## 6        1 48.00  26.5500      0
\end{verbatim}

\noindent \textbf{Model}. In a binary model, a dependent (outcome)
variable \(y_i\) takes only two values, i.e., \(y_i \in \{0, 1\}\). A
binary variable is sometimes called a \emph{dummy} variable. In this
application, the outcome variable is \texttt{survived}. Explanatory
variables are \texttt{female}, \texttt{age}, and \texttt{fare}. The
regression function is \begin{equation*}
  \begin{split}
    &E[survived | female, age, fare] \\
    =& \mathbb{P}[survived = 1 | female, age, fare]
    = G(\beta_0 + \beta_1 female + \beta_2 age + \beta_3 fare).
  \end{split}
\end{equation*} The function \(G(\cdot)\) is arbitrary function. In
practice, we often use following three specifications:

\begin{itemize}
\tightlist
\item
  Linear probability model (LPM):
  \(G(\mathbf{x}_i \beta) = \mathbf{x}_i \beta\).
\item
  Probit model: \(G(\mathbf{x}_i \beta) = \Phi(\mathbf{x}_i \beta)\)
  where \(\Phi(\cdot)\) is the standard Gaussian cumulative function.
\item
  Logit model:
  \(G(\mathbf{x}_i \beta) = 1/(1 + \exp(-\mathbf{x}_i \beta))\).
\end{itemize}

\hypertarget{linear-probability-model}{%
\subsection{Linear Probability Model}\label{linear-probability-model}}

The linear probability model specifys that \(G(a)\) is linear in \(a\),
that is, \begin{equation*}
  \mathbb{P}[survived = 1 | female, age, fare]
  = \beta_0 + \beta_1 female + \beta_2 age + \beta_3 fare.
\end{equation*} This model can be estimated using the OLS method. In
\texttt{R}, we can use the OLS method, running \texttt{lm()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model \textless{}{-}}\StringTok{ }\NormalTok{survived }\OperatorTok{\textasciitilde{}}\StringTok{ }\KeywordTok{factor}\NormalTok{(female) }\OperatorTok{+}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{fare}
\NormalTok{LPM \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(model, }\DataTypeTok{data =}\NormalTok{ train\_dt)}
\end{Highlighting}
\end{Shaded}

However, \texttt{lm()} function does not deal with heteroskedasticity
problem. To resolve it, we need to claculate heteroskedasticity-robust
standard errors using the White method. \begin{equation*}
  \hat{V}(\hat{\beta}) =
  \left( \frac{1}{n} \sum_i \mathbf{x}'_i \mathbf{x}_i  \right)^{-1}
  \left( \frac{1}{n} \sum_i \hat{u}_i^2 \mathbf{x}'_i \mathbf{x}_i \right)
  \left( \frac{1}{n} \sum_i \mathbf{x}'_i \mathbf{x}_i \right)^{-1}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# heteroskedasticity{-}robust standard errors}
\NormalTok{train\_dt}\OperatorTok{$}\StringTok{"(Intercept)"}\NormalTok{ \textless{}{-}}\StringTok{ }\DecValTok{1}
\NormalTok{X \textless{}{-}}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(train\_dt[,}\KeywordTok{c}\NormalTok{(}\StringTok{"(Intercept)"}\NormalTok{, }\StringTok{"female"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)])}
\NormalTok{u \textless{}{-}}\StringTok{ }\KeywordTok{diag}\NormalTok{(LPM}\OperatorTok{$}\NormalTok{residuals}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}

\NormalTok{XX \textless{}{-}}\StringTok{ }\KeywordTok{t}\NormalTok{(X) }\OperatorTok{\%*\%}\StringTok{ }\NormalTok{X}
\NormalTok{avgXX \textless{}{-}}\StringTok{ }\NormalTok{XX }\OperatorTok{*}\StringTok{ }\KeywordTok{nrow}\NormalTok{(X)}\OperatorTok{\^{}}\NormalTok{\{}\OperatorTok{{-}}\DecValTok{1}\NormalTok{\}}
\NormalTok{inv\_avgXX \textless{}{-}}\StringTok{ }\KeywordTok{solve}\NormalTok{(avgXX)}

\NormalTok{uXX \textless{}{-}}\StringTok{ }\KeywordTok{t}\NormalTok{(X) }\OperatorTok{\%*\%}\StringTok{ }\NormalTok{u }\OperatorTok{\%*\%}\StringTok{ }\NormalTok{X}
\NormalTok{avguXX \textless{}{-}}\StringTok{ }\NormalTok{uXX }\OperatorTok{*}\StringTok{ }\KeywordTok{nrow}\NormalTok{(X)}\OperatorTok{\^{}}\NormalTok{\{}\OperatorTok{{-}}\DecValTok{1}\NormalTok{\} }

\NormalTok{vcov\_b \textless{}{-}}\StringTok{ }\NormalTok{(inv\_avgXX }\OperatorTok{\%*\%}\StringTok{ }\NormalTok{avguXX }\OperatorTok{\%*\%}\StringTok{ }\NormalTok{inv\_avgXX) }\OperatorTok{*}\StringTok{ }\KeywordTok{nrow}\NormalTok{(X)}\OperatorTok{\^{}}\NormalTok{\{}\OperatorTok{{-}}\DecValTok{1}\NormalTok{\}}
\NormalTok{rse\_b \textless{}{-}}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{diag}\NormalTok{(vcov\_b))}

\NormalTok{label \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"(Intercept)"}\NormalTok{, }\StringTok{"factor(female)1"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)}
\KeywordTok{names}\NormalTok{(rse\_b) \textless{}{-}}\StringTok{ }\NormalTok{label}

\CommentTok{\# homoskedasticity{-}based standard errors}
\NormalTok{se\_b \textless{}{-}}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{diag}\NormalTok{(}\KeywordTok{vcov}\NormalTok{(LPM)))}

\KeywordTok{print}\NormalTok{(}\StringTok{"The Variance of OLS"}\NormalTok{); }\KeywordTok{vcov}\NormalTok{(LPM)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The Variance of OLS"
\end{verbatim}

\begin{verbatim}
##                   (Intercept) factor(female)1           age          fare
## (Intercept)      1.505787e-03   -3.905773e-04 -3.676396e-05 -5.951346e-07
## factor(female)1 -3.905773e-04    1.089299e-03  2.569835e-06 -2.154400e-06
## age             -3.676396e-05    2.569835e-06  1.264948e-06 -6.274261e-08
## fare            -5.951346e-07   -2.154400e-06 -6.274261e-08  9.167801e-08
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The Robust variance of OLS"}\NormalTok{); vcov\_b}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The Robust variance of OLS"
\end{verbatim}

\begin{verbatim}
##               (Intercept)        female           age          fare
## (Intercept)  1.810499e-03 -3.968956e-04 -4.601203e-05  8.979498e-07
## female      -3.968956e-04  1.239665e-03  4.975911e-06 -4.566026e-06
## age         -4.601203e-05  4.975911e-06  1.476806e-06 -7.956793e-08
## fare         8.979498e-07 -4.566026e-06 -7.956793e-08  7.846876e-08
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The Robust se using White method"}\NormalTok{); rse\_b}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The Robust se using White method"
\end{verbatim}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##    0.0425499596    0.0352088828    0.0012152389    0.0002801228
\end{verbatim}

Using the package \texttt{lmtest} and \texttt{sandwich} is the easiest
way to calculate heteroskedasticity-robust standard errors.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lmtest) }\CommentTok{\#use function \textasciigrave{}coeftest\textasciigrave{}}
\KeywordTok{library}\NormalTok{(sandwich) }\CommentTok{\#use function \textasciigrave{}vcovHC\textasciigrave{}}
\KeywordTok{coeftest}\NormalTok{(LPM, }\DataTypeTok{vcov =} \KeywordTok{vcovHC}\NormalTok{(LPM, }\DataTypeTok{type =} \StringTok{"HC0"}\NormalTok{))[, }\StringTok{"Std. Error"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##    0.0425499596    0.0352088828    0.0012152389    0.0002801228
\end{verbatim}

Finally, we summarize results of linear probability model in table
\ref{LPM}. We will discuss interpretation of results and goodness-of-fit
of LPM later.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(stargazer)}
\KeywordTok{stargazer}\NormalTok{(}
\NormalTok{  LPM, LPM,}
  \DataTypeTok{se =} \KeywordTok{list}\NormalTok{(se\_b, rse\_b),}
  \DataTypeTok{t.auto =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{p.auto =} \OtherTok{FALSE}\NormalTok{,}
  \DataTypeTok{report =} \StringTok{"vcs"}\NormalTok{, }\DataTypeTok{keep.stat =} \KeywordTok{c}\NormalTok{(}\StringTok{"n"}\NormalTok{),}
  \DataTypeTok{covariate.labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Female = 1"}\NormalTok{),}
  \DataTypeTok{add.lines =} \KeywordTok{list}\NormalTok{(}
    \KeywordTok{c}\NormalTok{(}\StringTok{"Standard errors"}\NormalTok{, }\StringTok{"Homoskedasticity{-}based"}\NormalTok{, }\StringTok{"Heteroskedasticity{-}robust"}\NormalTok{)),}
  \DataTypeTok{title =} \StringTok{"Results of Linear Probability Model"}\NormalTok{, }\DataTypeTok{label =} \StringTok{"LPM"}\NormalTok{,}
  \DataTypeTok{type =} \StringTok{"latex"}\NormalTok{, }\DataTypeTok{header =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{font.size =} \StringTok{"small"}\NormalTok{,}
  \DataTypeTok{omit.table.layout =} \StringTok{"n"}\NormalTok{, }\DataTypeTok{table.placement =} \StringTok{"h"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[h] \centering 
  \caption{Results of Linear Probability Model} 
  \label{LPM} 
\small 
\begin{tabular}{@{\extracolsep{5pt}}lcc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{2}{c}{\textit{Dependent variable:}} \\ 
\cline{2-3} 
\\[-1.8ex] & \multicolumn{2}{c}{survived} \\ 
\\[-1.8ex] & (1) & (2)\\ 
\hline \\[-1.8ex] 
 Female = 1 & 0.512 & 0.512 \\ 
  & (0.033) & (0.035) \\ 
  & & \\ 
 age & $-$0.003 & $-$0.003 \\ 
  & (0.001) & (0.001) \\ 
  & & \\ 
 fare & 0.001 & 0.001 \\ 
  & (0.0003) & (0.0003) \\ 
  & & \\ 
 Constant & 0.245 & 0.245 \\ 
  & (0.039) & (0.043) \\ 
  & & \\ 
\hline \\[-1.8ex] 
Standard errors & Homoskedasticity-based & Heteroskedasticity-robust \\ 
Observations & 696 & 696 \\ 
\hline 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table}

\hypertarget{probit-and-logit-model}{%
\subsection{Probit and Logit Model}\label{probit-and-logit-model}}

Unlike LPM, the probit and logit model must be estimated using the ML
method. The probability of observing \(y_i\) is \begin{equation*}
  p_{\beta}(y_i|\mathbf{x}_i)  
  = \mathbb{P}(y_i = 1 | x_i)^{y_i} [1 - \mathbb{P}(y_i = 1 | x_i)]^{1-y_i}
  = G(\mathbf{x}_i \beta)^{y_i} (1 - G(\mathbf{x}_i \beta))^{1-y_i}.
\end{equation*} Taking logalithm yields \begin{equation*}
  \log p_{\beta}(y_i|\mathbf{x}_i) = y_i \log(G(\mathbf{x}_i \beta)) + (1 - y_i)\log(1 - G(\mathbf{x}_i \beta)).
\end{equation*} The log-likelihood is \begin{equation*}
  M_n(\beta) = \sum_{i=1}^n \log p_{\beta}(y_i|\mathbf{x}_i).
\end{equation*}

The MLE \(\hat{\beta}\) holds that the score, which is the first-order
derivatives with respect to \(\beta\), is equal to 0. That is
\(\nabla_{\beta} M_n(\hat{\beta}) = 0\). For both logit and probit
model, the Hessian matrix, \(\nabla^2_{\beta\beta'} M_n(\beta)\), is
always negative definite. This implies that log-likelihood function
based on both models is grobally concave, and ensures that the MLE
maximizes the log-likelihood function. The first-order condition of the
probit model is \begin{equation*}
  \nabla_{\beta} M_n(\hat{\beta}) 
  = \sum_{i = 1}^n \left( y_i - \Phi(\mathbf{x}_i \hat{\beta}) \right) 
  \frac{\phi(\mathbf{x}_i \hat{\beta})}{\Phi(\mathbf{x}_i \hat{\beta})(1 - \phi(\mathbf{x}_i \hat{\beta}))} = 0.
\end{equation*} The first-order condition of the logit model is
\begin{equation*}
  \nabla_{\beta} M_n(\hat{\beta}) 
  = \sum_{i = 1}^n \left( y_i - G(\mathbf{x}_i \hat{\beta}) \right) \mathbf{x}'_i = 0.
\end{equation*} Since it is hard for us to solve this condition
analytically, we obtain estimators using numerical procedure.

The asymptotic distribution of \(\hat{\beta}\) is
\(\hat{\beta} \overset{d}{\to} N(\beta, \Sigma_{\beta})\) where
\begin{equation*}
  \Sigma_{\beta} = - \left( \sum_i E[E[ \nabla^2_{\beta\beta'} \log p_{\beta}(y_i | \mathbf{x}_i) | \mathbf{x}_i ]] \right)^{-1}.
\end{equation*} In practice, we replace
\(E[E[ \nabla^2_{\beta\beta'} \log p_{\beta}(y_i | \mathbf{x}_i) | \mathbf{x}_i ]]\)
by \begin{equation*}
  \frac{1}{n} \sum_i \nabla^2_{\beta\beta'} \log p_{\hat{\beta}}(y_i | \mathbf{x}_i),
\end{equation*} that is, \begin{equation*}
  \hat{\Sigma}_{\beta} = \left( \sum_i \nabla^2_{\beta\beta'} (-\log p_{\hat{\beta}}(y_i | \mathbf{x}_i)) \right)^{-1}.
\end{equation*}

In \texttt{R}, the function \texttt{nlm()} provides the Newton-Raphson
algorithm to minimize the function \footnote{\texttt{optim()} function
  is an another way to minimize the function. Especially, the function
  \texttt{optim(method\ =\ "BFGS")} provides the Quasi-Newton algorithm
  which carries on the spirit of Newton method.}. To run this function,
we need to define the log-likelihood function (\texttt{LnLik})
beforehand. Moreover, since we need to give initial values in augments,
we use coefficients estimated by OLS. Alternatively, we often use
\texttt{glm()} function. Using this function, we do not need to define
the log-likelihood function and initial values. Since estimates of
\texttt{glm()} are approximate to estiamtes of \texttt{nlm()}, we can
use this command safely. In this application, we use \texttt{nlm}
function to minimize the log-likelihood function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y \textless{}{-}}\StringTok{ }\NormalTok{train\_dt}\OperatorTok{$}\NormalTok{survived}
\NormalTok{female \textless{}{-}}\StringTok{ }\NormalTok{train\_dt}\OperatorTok{$}\NormalTok{female}
\NormalTok{age \textless{}{-}}\StringTok{ }\NormalTok{train\_dt}\OperatorTok{$}\NormalTok{age}
\NormalTok{fare \textless{}{-}}\StringTok{ }\NormalTok{train\_dt}\OperatorTok{$}\NormalTok{fare}

\CommentTok{\# log{-}likelihood}
\NormalTok{LnLik \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(b, }\DataTypeTok{model =} \KeywordTok{c}\NormalTok{(}\StringTok{"probit"}\NormalTok{, }\StringTok{"logit"}\NormalTok{)) \{}

\NormalTok{  xb \textless{}{-}}\StringTok{ }\NormalTok{b[}\DecValTok{1}\NormalTok{]}\OperatorTok{+}\StringTok{ }\NormalTok{b[}\DecValTok{2}\NormalTok{]}\OperatorTok{*}\NormalTok{female }\OperatorTok{+}\StringTok{ }\NormalTok{b[}\DecValTok{3}\NormalTok{]}\OperatorTok{*}\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{b[}\DecValTok{4}\NormalTok{]}\OperatorTok{*}\NormalTok{fare}

  \ControlFlowTok{if}\NormalTok{ (model }\OperatorTok{==}\StringTok{ "probit"}\NormalTok{) \{}
\NormalTok{    L \textless{}{-}}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(xb)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    L \textless{}{-}}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{{-}}\NormalTok{xb))}
\NormalTok{  \}}

\NormalTok{  LL\_i \textless{}{-}}\StringTok{ }\NormalTok{Y }\OperatorTok{*}\StringTok{ }\KeywordTok{log}\NormalTok{(L) }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{{-}}\StringTok{ }\NormalTok{Y) }\OperatorTok{*}\StringTok{ }\KeywordTok{log}\NormalTok{(}\DecValTok{1} \OperatorTok{{-}}\StringTok{ }\NormalTok{L)}
\NormalTok{  LL \textless{}{-}}\StringTok{ }\OperatorTok{{-}}\KeywordTok{sum}\NormalTok{(LL\_i)}

  \KeywordTok{return}\NormalTok{(LL)}
\NormalTok{\}}

\CommentTok{\#Newton{-}Raphson}
\NormalTok{init \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.169}\NormalTok{, }\FloatTok{0.520}\NormalTok{, }\FloatTok{{-}0.0002}\NormalTok{, }\FloatTok{0.001}\NormalTok{)}
\NormalTok{probit \textless{}{-}}\StringTok{ }\KeywordTok{nlm}\NormalTok{(LnLik, init, }\DataTypeTok{model =} \StringTok{"probit"}\NormalTok{, }\DataTypeTok{hessian =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{label \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"(Intercept)"}\NormalTok{, }\StringTok{"factor(female)1"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)}
\KeywordTok{names}\NormalTok{(probit}\OperatorTok{$}\NormalTok{estimate) \textless{}{-}}\StringTok{ }\NormalTok{label}
\KeywordTok{colnames}\NormalTok{(probit}\OperatorTok{$}\NormalTok{hessian) \textless{}{-}}\StringTok{ }\NormalTok{label; }\KeywordTok{rownames}\NormalTok{(probit}\OperatorTok{$}\NormalTok{hessian) \textless{}{-}}\StringTok{ }\NormalTok{label}

\NormalTok{b\_probit \textless{}{-}}\StringTok{ }\NormalTok{probit}\OperatorTok{$}\NormalTok{estimate}
\NormalTok{vcov\_probit \textless{}{-}}\StringTok{ }\KeywordTok{solve}\NormalTok{(probit}\OperatorTok{$}\NormalTok{hessian); se\_probit \textless{}{-}}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{diag}\NormalTok{(vcov\_probit))}
\NormalTok{LL\_probit \textless{}{-}}\StringTok{ }\OperatorTok{{-}}\NormalTok{probit}\OperatorTok{$}\NormalTok{minimum}

\CommentTok{\#glm function}
\NormalTok{model \textless{}{-}}\StringTok{ }\NormalTok{survived }\OperatorTok{\textasciitilde{}}\StringTok{ }\KeywordTok{factor}\NormalTok{(female) }\OperatorTok{+}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{fare}
\NormalTok{probit\_glm \textless{}{-}}\StringTok{ }\KeywordTok{glm}\NormalTok{(model, }\DataTypeTok{data =}\NormalTok{ train\_dt, }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\StringTok{"probit"}\NormalTok{))}

\CommentTok{\#result}
\KeywordTok{print}\NormalTok{(}\StringTok{"The MLE of probit model using nlm"}\NormalTok{); b\_probit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The MLE of probit model using nlm"
\end{verbatim}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##    -0.740010404     1.440663450    -0.009316882     0.006302940
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The Variance of probit model using nlm"}\NormalTok{); vcov\_probit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The Variance of probit model using nlm"
\end{verbatim}

\begin{verbatim}
##                   (Intercept) factor(female)1           age          fare
## (Intercept)      1.764185e-02   -4.735516e-03 -4.149486e-04 -2.453847e-05
## factor(female)1 -4.735516e-03    1.255295e-02  8.495496e-06 -5.592007e-06
## age             -4.149486e-04    8.495496e-06  1.512962e-05 -9.929199e-07
## fare            -2.453847e-05   -5.592007e-06 -9.929199e-07  1.737151e-06
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The se of probit model using nlm"}\NormalTok{); se\_probit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The se of probit model using nlm"
\end{verbatim}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##     0.132822608     0.112039969     0.003889681     0.001318010
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The coefficients of probit using glm"}\NormalTok{); }\KeywordTok{coef}\NormalTok{(probit\_glm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The coefficients of probit using glm"
\end{verbatim}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##    -0.740094134     1.440662013    -0.009314690     0.006303577
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The se of probit using glm"}\NormalTok{); }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{diag}\NormalTok{(}\KeywordTok{vcov}\NormalTok{(probit\_glm)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The se of probit using glm"
\end{verbatim}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##     0.134738833     0.112061942     0.003966673     0.001326048
\end{verbatim}

Using \texttt{LogLik}, we can also estimate logit model by
Newton-Raphson algorithm. To compare result, we also use \texttt{glm()}
function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Newton{-}Raphson}
\NormalTok{logit \textless{}{-}}\StringTok{ }\KeywordTok{nlm}\NormalTok{(LnLik, init, }\DataTypeTok{model =} \StringTok{"logit"}\NormalTok{, }\DataTypeTok{hessian =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{label \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"(Intercept)"}\NormalTok{, }\StringTok{"factor(female)1"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)}
\KeywordTok{names}\NormalTok{(logit}\OperatorTok{$}\NormalTok{estimate) \textless{}{-}}\StringTok{ }\NormalTok{label}
\KeywordTok{colnames}\NormalTok{(logit}\OperatorTok{$}\NormalTok{hessian) \textless{}{-}}\StringTok{ }\NormalTok{label; }\KeywordTok{rownames}\NormalTok{(logit}\OperatorTok{$}\NormalTok{hessian) \textless{}{-}}\StringTok{ }\NormalTok{label}

\NormalTok{b\_logit \textless{}{-}}\StringTok{ }\NormalTok{logit}\OperatorTok{$}\NormalTok{estimate}
\NormalTok{vcov\_logit \textless{}{-}}\StringTok{ }\KeywordTok{solve}\NormalTok{(logit}\OperatorTok{$}\NormalTok{hessian); se\_logit \textless{}{-}}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{diag}\NormalTok{(vcov\_logit))}
\NormalTok{LL\_logit \textless{}{-}}\StringTok{ }\OperatorTok{{-}}\NormalTok{logit}\OperatorTok{$}\NormalTok{minimum}

\CommentTok{\#glm function}
\NormalTok{logit\_glm \textless{}{-}}\StringTok{ }\KeywordTok{glm}\NormalTok{(model, }\DataTypeTok{data =}\NormalTok{ train\_dt, }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\StringTok{"logit"}\NormalTok{))}

\CommentTok{\#result}
\KeywordTok{print}\NormalTok{(}\StringTok{"The MLE of logit model"}\NormalTok{); b\_logit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The MLE of logit model"
\end{verbatim}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##     -1.19071868      2.36579523     -0.01665811      0.01049121
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The Variance of logit model"}\NormalTok{); vcov\_logit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The Variance of logit model"
\end{verbatim}

\begin{verbatim}
##                   (Intercept) factor(female)1           age          fare
## (Intercept)      5.347251e-02   -1.306856e-02 -1.260674e-03 -7.166131e-05
## factor(female)1 -1.306856e-02    3.678907e-02 -4.389835e-05 -2.773805e-06
## age             -1.260674e-03   -4.389835e-05  4.703086e-05 -3.343743e-06
## fare            -7.166131e-05   -2.773805e-06 -3.343743e-06  5.199195e-06
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The se of logit model"}\NormalTok{); se\_logit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The se of logit model"
\end{verbatim}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##     0.231241234     0.191804780     0.006857905     0.002280174
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The coefficients of logit using glm"}\NormalTok{); }\KeywordTok{coef}\NormalTok{(logit\_glm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The coefficients of logit using glm"
\end{verbatim}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##     -1.19080405      2.36579304     -0.01665588      0.01049185
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\StringTok{"The se of logit using glm"}\NormalTok{); }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{diag}\NormalTok{(}\KeywordTok{vcov}\NormalTok{(logit\_glm)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The se of logit using glm"
\end{verbatim}

\begin{verbatim}
##     (Intercept) factor(female)1             age            fare 
##     0.231133819     0.191810415     0.006862245     0.002272391
\end{verbatim}

As a result, table \ref{probit_logit} summarizes results of probit model
and logit model. Standard errors are in parentheses. We will discuss
interpretation of results and goodness-of-fit later.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{stargazer}\NormalTok{(}
\NormalTok{  probit\_glm, logit\_glm,}
  \DataTypeTok{coef =} \KeywordTok{list}\NormalTok{(b\_probit, b\_logit), }\DataTypeTok{se =} \KeywordTok{list}\NormalTok{(se\_probit, se\_logit),}
  \DataTypeTok{t.auto =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{p.auto =} \OtherTok{FALSE}\NormalTok{,}
  \DataTypeTok{report =} \StringTok{"vcs"}\NormalTok{, }\DataTypeTok{keep.stat =} \KeywordTok{c}\NormalTok{(}\StringTok{"n"}\NormalTok{),}
  \DataTypeTok{covariate.labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Female = 1"}\NormalTok{),}
  \DataTypeTok{add.lines =} \KeywordTok{list}\NormalTok{(}
    \KeywordTok{c}\NormalTok{(}\StringTok{"Log{-}Likelihood"}\NormalTok{, }\KeywordTok{round}\NormalTok{(LL\_probit, }\DecValTok{3}\NormalTok{), }\KeywordTok{round}\NormalTok{(LL\_logit, }\DecValTok{3}\NormalTok{))),}
  \DataTypeTok{title =} \StringTok{"Results of Probit and Logit model"}\NormalTok{,}
  \DataTypeTok{label =} \StringTok{"probit\_logit"}\NormalTok{,}
  \DataTypeTok{type =} \StringTok{"latex"}\NormalTok{, }\DataTypeTok{header =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{font.size =} \StringTok{"small"}\NormalTok{,}
  \DataTypeTok{table.placement =} \StringTok{"h"}\NormalTok{, }\DataTypeTok{omit.table.layout =} \StringTok{"n"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[h] \centering 
  \caption{Results of Probit and Logit model} 
  \label{probit_logit} 
\small 
\begin{tabular}{@{\extracolsep{5pt}}lcc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{2}{c}{\textit{Dependent variable:}} \\ 
\cline{2-3} 
\\[-1.8ex] & \multicolumn{2}{c}{survived} \\ 
\\[-1.8ex] & \textit{probit} & \textit{logistic} \\ 
\\[-1.8ex] & (1) & (2)\\ 
\hline \\[-1.8ex] 
 Female = 1 & 1.441 & 2.366 \\ 
  & (0.112) & (0.192) \\ 
  & & \\ 
 age & $-$0.009 & $-$0.017 \\ 
  & (0.004) & (0.007) \\ 
  & & \\ 
 fare & 0.006 & 0.010 \\ 
  & (0.001) & (0.002) \\ 
  & & \\ 
 Constant & $-$0.740 & $-$1.191 \\ 
  & (0.133) & (0.231) \\ 
  & & \\ 
\hline \\[-1.8ex] 
Log-Likelihood & -351.507 & -351.873 \\ 
Observations & 696 & 696 \\ 
\hline 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table}

\hypertarget{interpretaions}{%
\subsection{Interpretaions}\label{interpretaions}}

In the linear probability model, interepretations of coefficients are
straight-forward. The coefficient \(\beta_1\) is the change in survival
probability given a one-unit increase in continuous variable \(x\). In
the case of discrete variable, the coefficient \(\beta_1\) is the
difference in survival probability between two groups.

However, when we use the probit or logit model, it is hard for us to
interepret results because the partial effect is not constant across
other covariates. As an illustration, the partial effect of continuous
variable \texttt{age} is \begin{equation*}
  \partial_{age} \mathbb{P}[survived = 1 | female, age, fare] =
  \begin{cases}
    \beta_2  &\text{if LPM}  \\
    \phi(\mathbf{x}_i \beta) \beta_2  &\text{if Probit}  \\
    \frac{\exp(-\mathbf{x}_i \beta)}{(1 + \exp(-\mathbf{x}_i \beta))^2} \beta_2 &\text{if Logit}
  \end{cases}.
\end{equation*} The partial effect of dummy variable \texttt{female} is
\begin{equation*}
  \begin{split}
  &\mathbb{P}[survived = 1 | female = 1, age, fare] - \mathbb{P}[survived = 1 | female = 0, age, fare] \\
  =& 
  \begin{cases}
    \beta_1 &\text{if LPM}  \\
    \Phi(\beta_0 + \beta_1 + \beta_2 age + \beta_3 fare) - \Phi(\beta_0 + \beta_2 age + \beta_3 fare)  &\text{if Probit}  \\
    \Lambda(\beta_0 + \beta_1 + \beta_2 age + \beta_3 fare) - \Lambda(\beta_0 + \beta_2 age + \beta_3 fare)  &\text{if Logit}
  \end{cases}
  \end{split},
\end{equation*} where \(\Lambda(a) = 1/(1 + \exp(-a))\).

Table \ref{titanic} shows results of linear probability model, probit
model, and logit model. All specifications shows that the survival
probability of female is about 50\% point higher than of male, which is
statistically significant. Moreover, the survival probability is
decreasing in age, which implies children are more likely to survive.
However, the size of coefficient is small. Overall, crews obeyed the
code of ``women and children first'', but the survival probability of
children is not largely different from of adult.

\hypertarget{model-fitness}{%
\subsection{Model Fitness}\label{model-fitness}}

There are two measurements of goodness-of-fit. First, the \emph{percent
correctly predicted} reports the percentage of unit whose predicted
\(y_i\) matches the actual \(y_i\). The predicted \(y_i\) takes one if
\(G(\mathbf{x}_i \hat{\beta}) > 0.5\), and takes zero if
\(G(\mathbf{x}_i \hat{\beta}) \le 0.5\). We calculate this index, using
the training data and the test data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# In{-}sample}
\NormalTok{in\_Y \textless{}{-}}\StringTok{ }\NormalTok{train\_dt}\OperatorTok{$}\NormalTok{survived}
\NormalTok{in\_X \textless{}{-}}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(train\_dt[,}\KeywordTok{c}\NormalTok{(}\StringTok{"(Intercept)"}\NormalTok{, }\StringTok{"female"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)])}

\NormalTok{in\_Xb\_lpm \textless{}{-}}\StringTok{ }\NormalTok{in\_X }\OperatorTok{\%*\%}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{coef}\NormalTok{(LPM), }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}
\NormalTok{in\_Xb\_probit \textless{}{-}}\StringTok{ }\NormalTok{in\_X }\OperatorTok{\%*\%}\StringTok{ }\KeywordTok{matrix}\NormalTok{(b\_probit, }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}
\NormalTok{in\_Xb\_logit \textless{}{-}}\StringTok{ }\NormalTok{in\_X }\OperatorTok{\%*\%}\StringTok{ }\KeywordTok{matrix}\NormalTok{(b\_logit, }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}

\NormalTok{in\_hatY\_lpm \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(in\_Xb\_lpm }\OperatorTok{\textgreater{}}\StringTok{ }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{in\_hatY\_probit \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\KeywordTok{pnorm}\NormalTok{(in\_Xb\_probit) }\OperatorTok{\textgreater{}}\StringTok{ }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{in\_hatY\_logit \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{{-}}\NormalTok{in\_Xb\_logit)) }\OperatorTok{\textgreater{}}\StringTok{ }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{in\_pcp\_lpm \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{sum}\NormalTok{(in\_Y }\OperatorTok{==}\StringTok{ }\NormalTok{in\_hatY\_lpm)}\OperatorTok{/}\KeywordTok{nrow}\NormalTok{(in\_X), }\DecValTok{4}\NormalTok{)}
\NormalTok{in\_pcp\_probit \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{sum}\NormalTok{(in\_Y }\OperatorTok{==}\StringTok{ }\NormalTok{in\_hatY\_probit)}\OperatorTok{/}\KeywordTok{nrow}\NormalTok{(in\_X), }\DecValTok{4}\NormalTok{)}
\NormalTok{in\_pcp\_logit \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{sum}\NormalTok{(in\_Y }\OperatorTok{==}\StringTok{ }\NormalTok{in\_hatY\_logit)}\OperatorTok{/}\KeywordTok{nrow}\NormalTok{(in\_X), }\DecValTok{4}\NormalTok{)}

\CommentTok{\# Out{-}of{-}sample}
\NormalTok{out\_Y \textless{}{-}}\StringTok{ }\NormalTok{test\_dt}\OperatorTok{$}\NormalTok{survived}
\NormalTok{test\_dt}\OperatorTok{$}\StringTok{"(Intercept)"}\NormalTok{ \textless{}{-}}\StringTok{ }\DecValTok{1}
\NormalTok{out\_X \textless{}{-}}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(test\_dt[,}\KeywordTok{c}\NormalTok{(}\StringTok{"(Intercept)"}\NormalTok{, }\StringTok{"female"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)])}

\NormalTok{out\_Xb\_lpm \textless{}{-}}\StringTok{ }\NormalTok{out\_X }\OperatorTok{\%*\%}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{coef}\NormalTok{(LPM), }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}
\NormalTok{out\_Xb\_probit \textless{}{-}}\StringTok{ }\NormalTok{out\_X }\OperatorTok{\%*\%}\StringTok{ }\KeywordTok{matrix}\NormalTok{(b\_probit, }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}
\NormalTok{out\_Xb\_logit \textless{}{-}}\StringTok{ }\NormalTok{out\_X }\OperatorTok{\%*\%}\StringTok{ }\KeywordTok{matrix}\NormalTok{(b\_logit, }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}

\NormalTok{out\_hatY\_lpm \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(out\_Xb\_lpm }\OperatorTok{\textgreater{}}\StringTok{ }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{out\_hatY\_probit \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\KeywordTok{pnorm}\NormalTok{(out\_Xb\_probit) }\OperatorTok{\textgreater{}}\StringTok{ }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{out\_hatY\_logit \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{{-}}\NormalTok{out\_Xb\_logit)) }\OperatorTok{\textgreater{}}\StringTok{ }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{out\_pcp\_lpm \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{sum}\NormalTok{(out\_Y }\OperatorTok{==}\StringTok{ }\NormalTok{out\_hatY\_lpm)}\OperatorTok{/}\KeywordTok{nrow}\NormalTok{(out\_X), }\DecValTok{4}\NormalTok{)}
\NormalTok{out\_pcp\_probit \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{sum}\NormalTok{(out\_Y }\OperatorTok{==}\StringTok{ }\NormalTok{out\_hatY\_probit)}\OperatorTok{/}\KeywordTok{nrow}\NormalTok{(out\_X), }\DecValTok{4}\NormalTok{)}
\NormalTok{out\_pcp\_logit \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{sum}\NormalTok{(out\_Y }\OperatorTok{==}\StringTok{ }\NormalTok{out\_hatY\_logit)}\OperatorTok{/}\KeywordTok{nrow}\NormalTok{(out\_X), }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Second measurement is the \emph{pseudo R-squared}. The pseudo R-squared
is obtained by \(1 - \sum_i \hat{u}_i^2/ \sum_i y_i^2\), where
\(\hat{u}_i = y_i - G(\mathbf{x}_i \hat{\beta})\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y2 \textless{}{-}}\StringTok{ }\NormalTok{in\_Y}\OperatorTok{\^{}}\DecValTok{2}

\NormalTok{hatu\_lpm \textless{}{-}}\StringTok{ }\NormalTok{(in\_Y }\OperatorTok{{-}}\StringTok{ }\NormalTok{in\_Xb\_lpm)}\OperatorTok{\^{}}\DecValTok{2}
\NormalTok{hatu\_probit \textless{}{-}}\StringTok{ }\NormalTok{(in\_Y }\OperatorTok{{-}}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(in\_Xb\_probit))}\OperatorTok{\^{}}\DecValTok{2}
\NormalTok{hatu\_logit \textless{}{-}}\StringTok{ }\NormalTok{(in\_Y }\OperatorTok{{-}}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{{-}}\NormalTok{in\_Xb\_logit)))}\OperatorTok{\^{}}\DecValTok{2}

\NormalTok{pr2\_lpm \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\DecValTok{1} \OperatorTok{{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{(hatu\_lpm)}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(Y2), }\DecValTok{4}\NormalTok{)}
\NormalTok{pr2\_probit \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\DecValTok{1} \OperatorTok{{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{(hatu\_probit)}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(Y2), }\DecValTok{4}\NormalTok{)}
\NormalTok{pr2\_logit \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\DecValTok{1} \OperatorTok{{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{(hatu\_logit)}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(Y2), }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Table \ref{titanic} summarizes two measurements of model fitness. There
is little difference among LPM, probit model, and logit model.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{stargazer}\NormalTok{(}
\NormalTok{  LPM, probit\_glm, logit\_glm,}
  \DataTypeTok{coef =} \KeywordTok{list}\NormalTok{(}\KeywordTok{coef}\NormalTok{(LPM), b\_probit, b\_logit),}
  \DataTypeTok{se =} \KeywordTok{list}\NormalTok{(rse\_b, se\_probit, se\_logit),}
  \DataTypeTok{t.auto =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{p.auto =} \OtherTok{FALSE}\NormalTok{,}
  \DataTypeTok{omit =} \KeywordTok{c}\NormalTok{(}\StringTok{"Constant"}\NormalTok{), }\DataTypeTok{covariate.labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Female = 1"}\NormalTok{),}
  \DataTypeTok{report =} \StringTok{"vcs"}\NormalTok{, }\DataTypeTok{keep.stat =} \KeywordTok{c}\NormalTok{(}\StringTok{"n"}\NormalTok{),}
  \DataTypeTok{add.lines =} \KeywordTok{list}\NormalTok{(}
    \KeywordTok{c}\NormalTok{(}\StringTok{"Percent correctly predicted (in{-}sample)"}\NormalTok{, }
\NormalTok{      in\_pcp\_lpm, in\_pcp\_probit, in\_pcp\_logit),}
    \KeywordTok{c}\NormalTok{(}\StringTok{"Percent correctly predicted (out{-}of{-}sample)"}\NormalTok{,}
\NormalTok{      out\_pcp\_lpm, out\_pcp\_probit, out\_pcp\_logit),}
    \KeywordTok{c}\NormalTok{(}\StringTok{"Pseudo R{-}squared"}\NormalTok{, pr2\_lpm, pr2\_probit, pr2\_logit)}
\NormalTok{  ),}
  \DataTypeTok{omit.table.layout =} \StringTok{"n"}\NormalTok{, }\DataTypeTok{table.placement =} \StringTok{"t"}\NormalTok{,}
  \DataTypeTok{title =} \StringTok{"Titanic Survivors: LPM, Probit, and Logit"}\NormalTok{,}
  \DataTypeTok{label =} \StringTok{"titanic"}\NormalTok{,}
  \DataTypeTok{type =} \StringTok{"latex"}\NormalTok{, }\DataTypeTok{header =} \OtherTok{FALSE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t] \centering 
  \caption{Titanic Survivors: LPM, Probit, and Logit} 
  \label{titanic} 
\begin{tabular}{@{\extracolsep{5pt}}lccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{3}{c}{\textit{Dependent variable:}} \\ 
\cline{2-4} 
\\[-1.8ex] & \multicolumn{3}{c}{survived} \\ 
\\[-1.8ex] & \textit{OLS} & \textit{probit} & \textit{logistic} \\ 
\\[-1.8ex] & (1) & (2) & (3)\\ 
\hline \\[-1.8ex] 
 Female = 1 & 0.512 & 1.441 & 2.366 \\ 
  & (0.035) & (0.112) & (0.192) \\ 
  & & & \\ 
 age & $-$0.003 & $-$0.009 & $-$0.017 \\ 
  & (0.001) & (0.004) & (0.007) \\ 
  & & & \\ 
 fare & 0.001 & 0.006 & 0.010 \\ 
  & (0.0003) & (0.001) & (0.002) \\ 
  & & & \\ 
\hline \\[-1.8ex] 
Percent correctly predicted (in-sample) & 0.7802 & 0.7744 & 0.7744 \\ 
Percent correctly predicted (out-of-sample) & 0.7794 & 0.7765 & 0.7765 \\ 
Pseudo R-squared & 0.5869 & 0.5873 & 0.5869 \\ 
Observations & 696 & 696 & 696 \\ 
\hline 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table}

\end{document}
